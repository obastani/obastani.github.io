<html>

<head>

<title>Osbert Bastani</title>

<link rel="stylesheet" href="index.css" type="text/css">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
<meta name=viewport content="width=device-width, initial-scale=1">

</head>

<body>

<div align=center>

<br/>
<br/>

<div class="all">
  
<div class="row txt">
  <div class="col-md-3 stitle">
    <img src="photo.jpg" alt="Osbert Bastani" width=120px>
  </div>
  <div class="col-md-7">
    <h1 style="margin-top:0px;">Osbert Bastani</h1>
    Research Assistant Professor
    <br/>
    University of Pennsylvania
    <br/>
    611 Levine Hall
    <br/>
    obastani[AT]seas.upenn.edu
    <br/>
    [<a href="./docs/cv.pdf">CV</a>]
  </div>
</div>

<br/>

<div class="row txt">
  <div class="col-md-3 stitle">about</div>
  <div class="col-md-7">
    <p>
      I am a research assistant professor at the Department of Computer and Information Science at the University of Pennsylvania. Previously, I completed my Ph.D. at Stanford advised by <a href="http://theory.stanford.edu/~aiken">Alex Aiken</a>, and spent a year as a postdoc at MIT working with <a href="https://people.csail.mit.edu/asolar/">Armando Solar-Lezama</a>.
    </p>
  </div>
</div>

<br/>

<div class="row txt">
  <div class="col-md-3 stitle">research</div>
  <div class="col-md-7">
    <p>
      I am broadly interested in machine learning and programming languages research. Recently, I have been working on developing trustworthy machine learning algorithms. Machine learning is increasingly used in real world systems where failures can be catastrophic, such as autonomous vehicles, medical diagnosis, and legal decision making. For such applications, there are many desirable correctness properties that machine learning models should satisfy, including safety, robustness, fairness, causality, and interpretability. My work aims to address the following challenges:
      <ul>
	<li>
	  What correctness properties should machine learning models satisfy?
	</li>
	<li>
	  How can we reason about the correctness of existing machine learning models?
	</li>
	<li>
	  Can we learn machine learning models for which correctness is easy to verify?
	</li>
      </ul>
    </p>
  </div>
</div>

<br/>

<div class="row txt">
  <div class="col-md-3 stitle">publications</div>
  <div class="col-md-7">
    <p>
      Osbert Bastani. Safe Reinforcement Learning via Online Shielding. In submission. [<a href="http://arxiv.org/abs/1905.10691">arXiv</a>]
    </p>
    <p>
      Osbert Bastani. Sample Complexity of Estimating the Policy Gradient for Nearly Deterministic Dynamical Systems. In submission. [<a href="https://arxiv.org/abs/1901.08562">arXiv</a>]
    </p>
    <p>
      Min Wen, Osbert Bastani, Ufuk Topcu. Fairness with Dynamics. In submission. [<a href="https://arxiv.org/abs/1901.08568">arXiv</a>]
    </p>
    <p>
      Carolyn Kim, Osbert Bastani. Learning Interpretable Models with Causal Guarantees. In submission. [<a href="https://arxiv.org/abs/1901.08576">arXiv</a>]
    </p>
    <p>
      Brian Heath, Neelay Velingker, Osbert Bastani, Mayur Naik. PolyDroid: Learning-Driven Specialization of Mobile Applications. In submission. [<a href="https://arxiv.org/abs/1902.09589">arXiv</a>]
    </p>
    <p>
      Osbert Bastani, Carolyn Kim, Hamsa Bastani. Interpreting Blackbox Models via Model Extraction. In submission. [<a href="https://arxiv.org/abs/1705.08504">arXiv</a>]
    </p>
    <p>
      Osbert Bastani, Xin Zhang, Armando Solar-Lezama. Verifying Fairness Properties via Concentration. Conditionally accepted, OOPSLA 2019. [<a href="https://arxiv.org/abs/1812.02573">arXiv</a>]
    </p>
    <p>
      Jia Chen, Jiayi Wei, Yu Feng, Osbert Bastani, Isil Dillig. Relational Verification using Reinforcement Learning. OOPSLA 2019.
    </p>
    <p>
      Zhengkai Wu, Evan Johnson, Wei Yang, Osbert Bastani, Dawn Song, Jian Peng, Tao Xie. REINAM: Reinforcement Learning for Input-Grammar Inference. FSE 2019. [<a href="./docs/fse19.pdf">paper</a>]
    </p>
    <p>
Arbaaz Khan, Chi Zhang, Shuo Li, Jiayue Wu, Brent Schlotfeldt, Sarah Tang, Alejandro Ribeiro, Osbert Bastani, Vijay Kumar. Learning Safe Unlabeled Multi-Robot Planning with Motion Constraints. IROS 2019.
    </p>
    <p>
      Halley Young, Osbert Bastani, Mayur Naik. Learning Neurosymbolic Generative Models via Program Synthesis. ICML 2019. [<a href="./docs/icml19.pdf">paper</a>] [<a href="./docs/icml19-extended.pdf">extended</a>] [<a href="https://arxiv.org/abs/1901.08565">arXiv</a>]
    </p>
    <p>
      Sadra Sadraddini, Shen Shen, Osbert Bastani. Polytopic Trees for Verification of Learning-Based Controllers. Workshop on NSV 2019. [<a href="./docs/nsv19.pdf">paper</a>]
    </p>
    <p>
      Osbert Bastani, Rahul Sharma, Lazaro Clapp, Saswat Anand, Alex Aiken. Eventually Sound Points-To Analysis with Missing Code. ECOOP 2019. [<a href="./docs/ecoop19.pdf">paper</a>] [<a href="./docs/ecoop19-extended.pdf">extended</a>] [<a href="https://arxiv.org/abs/1711.03436">arXiv</a>]
    </p>
    <p>
      Osbert Bastani, Yewen Pu, Armando Solar-Lezama. Verifiable Reinforcement Learning via Policy Extraction. NeurIPS 2018. [<a href="./docs/neurips18.pdf">paper</a>] [<a href="http://arxiv.org/abs/1805.08328">arXiv</a>] [<a href="./docs/viper-presentation.pdf">presentation</a>] [<a href="./docs/plmw18-poster.pdf">poster</a>] [<a href="https://github.com/obastani/viper">code</a>]
    </p>
    <p>
      Osbert Bastani, Rahul Sharma, Alex Aiken, Percy Liang. Active Learning of Points-To Specifications. PLDI 2018. [<a href="./docs/pldi18a.pdf">paper</a>] [<a href="./docs/pldi18a-extended.pdf">extended</a>] [<a href="https://arxiv.org/abs/1711.03239">arXiv</a>] [<a href="./docs/pldi18a-presentation.pdf">presentation</a>] [<a href="https://github.com/obastani/atlas">code</a>]
    </p>
    <p>
      Yu Feng, Ruben Martins, Osbert Bastani, Isil Dillig. Program Synthesis using Conflict-Driven Learning. PLDI 2018 (Distinguished Paper). [<a href="./docs/pldi18b.pdf">paper</a>] [<a href="https://arxiv.org/abs/1711.08029">arXiv</a>]
    </p>
    <p>
      Osbert Bastani, Yani Ioannou, Leonidas Lampropoulos, Dimitrios Vytiniotis, Aditya Nori, Antonio Criminisi. Measuring Neural Net Robustness with Constraints. DARS Workshop 2018 (Invited Paper). [<a href="./docs/dars18.pdf">paper</a>]  [<a href="./docs/dars18-presentation.pdf">presentation</a>]
    </p>
    <p>
      Osbert Bastani. Beyond Deductive Inference in Program Analysis. Ph.D. Thesis. [<a href="./docs/thesis.pdf">thesis</a>] [<a href="./docs/defense.pdf">defense</a>]
    </p>
    <p>
      Osbert Bastani, Carolyn Kim, Hamsa Bastani. Interpretability via Model Extraction. FAT/ML Workshop 2017. [<a href="./docs/fatml17.pdf">paper</a>] [<a href="https://arxiv.org/abs/1706.09773">arxiv</a>] [<a href="./docs/fatml17-poster.pdf">poster</a>] [<a href="https://github.com/obastani/dtextract">code</a>]
    </p>
    <p>
      Osbert Bastani, Rahul Sharma, Alex Aiken, Percy Liang. Synthesizing Program Input Grammars. PLDI 2017. [<a href="./docs/pldi17.pdf">paper</a>] [<a href="./docs/pldi17-extended.pdf">extended</a>] [<a href="http://arxiv.org/abs/1608.01723">arXiv</a>] [<a href="./docs/pldi17-presentation.pdf">presentation</a>] [<a href="https://github.com/obastani/glade">code</a>]
    </p>
    <p>
      Yu Feng, Osbert Bastani, Ruben Martins, Isil Dillig, Saswat Anand. Automated Synthesis of Semantic Malware Signatures using Maximum Satisfiability. NDSS 2017. [<a href="./docs/ndss17.pdf">paper</a>] [<a href="http://arxiv.org/abs/1608.06254">arXiv</a>]
    </p>
    <p>
      Osbert Bastani, Yani Ioannou, Leonidas Lampropoulos, Dimitrios Vytiniotis, Aditya Nori, Antonio Criminisi. Measuring Neural Net Robustness with Constraints. NIPS 2016. [<a href="./docs/nips16.pdf">paper</a>] [<a href="http://arxiv.org/abs/1605.07262">arXiv</a>] [<a href="./docs/nips16-poster.pdf">poster</a>] [<a href="https://github.com/Microsoft/NeuralNetworkAnalysis">code</a>]
    </p>
    <p>
      Lazaro Clapp, Osbert Bastani, Saswat Anand, Alex Aiken. Minimizing GUI Event Traces. FSE 2016. [<a href="./docs/fse16.pdf">paper</a>]
    </p>
    <p>
      Osbert Bastani, Saswat Anand, Alex Aiken. An interactive approach to mobile app verification. MobileDeLi Workshop 2015 (Invited Paper). [<a href="./docs/mobiledeli15.pdf">paper</a>]
    </p>
    <p>
      Osbert Bastani, Saswat Anand, Alex Aiken. Interactively verifying absence of explicit information flows in Android apps. OOPSLA 2015. [<a href="./docs/oopsla15.pdf">paper</a>] [<a href="./docs/oopsla15-presentation.pdf">presentation</a>]
    </p>
    <p>
      Osbert Bastani, Saswat Anand, Alex Aiken. Specification inference using context-free reachability. POPL 2015. [<a href="./docs/popl15.pdf">paper</a>] [<a href="./docs/popl15-presentation.pdf">presentation</a>]
    </p>
    <p>
      Osbert Bastani, Christopher Hillar, Dimitar Popov, Maurice Rojas. Randomization, sums of squares, near-circuits, and faster real root counting. Contemporary Mathematics 556 (2011): 145-166. [<a href="./docs/contemporary-math-2011.pdf">paper</a>]
    </p>
  </div>
</div>

<br/>
<br/>

</body>
</html>
